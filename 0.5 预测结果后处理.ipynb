{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file PosixPath('/home/octusr3/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc'), line 260 ('font.family:  sans-serif')\n",
      "Duplicate key in file PosixPath('/home/octusr3/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc'), line 268 ('font.sans-serif: DejaVu Sans, Bitstream Vera Sans, Computer Modern Sans Serif, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif')\n",
      "Duplicate key in file PosixPath('/home/octusr3/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc'), line 411 ('axes.unicode_minus: True  # use Unicode for the minus symbol rather than hyphen.  See')\n",
      "/home/octusr3/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from oct_Utils import *\n",
    "root_path = '/home/octusr3/project/oct/output'\n",
    "exp_name = '1102/disc_num_r50_512'#/home/octusr3/project/oct/output/0918/disc_num_r50_380/exp-pid/results/valid-loss/data.csv\n",
    "df = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mask ='''[[0 0 0 0 0 0 0 0 0 0]\n",
    "                [0 0 0 1 1 1 1 0 0 0]\n",
    "                [0 0 1 1 1 1 1 1 0 0]\n",
    "                [0 1 1 1 1 1 1 1 1 0]\n",
    "                [1 1 1 1 1 1 1 1 1 0]\n",
    "                [1 1 1 1 1 1 1 1 1 0]\n",
    "                [0 1 1 1 1 1 1 1 1 0]\n",
    "                [0 0 1 1 1 1 1 1 0 0]\n",
    "                [0 0 0 1 1 1 1 0 0 0]\n",
    "                [0 0 0 0 0 0 0 0 0 0]]'''\n",
    "\n",
    "od_valid_mask = str_to_np_mat(valid_mask) == 1\n",
    "\n",
    "\n",
    "def restore_pred_matrix(row):\n",
    "    result = np.zeros((10, 10), dtype=float)\n",
    "    result[od_valid_mask] = str_to_np_array(row['pred'])#相当于把valid_point的地方,也就是矩阵为True的地方，赋值给pred,按照一行一行的顺序排列数据。\n",
    "    if row['eye'] == 'OS':\n",
    "        result = np.flip(result, axis=1)\n",
    "    return result\n",
    "\n",
    "def restore_pred_list(row):\n",
    "    mat = restore_pred_matrix(row)\n",
    "    if row['eye'] == 'OS':\n",
    "        mat = np.flip(mat, axis=1)\n",
    "    return mat[od_valid_mask].tolist()\n",
    "\n",
    "def convert_num_to_list(row):\n",
    "    mat = str_to_np_mat(row['num'])\n",
    "    if row['eye'] == 'OS':\n",
    "        mat = np.flip(mat, axis=1)\n",
    "    return mat[od_valid_mask].tolist()\n",
    "\n",
    "df['pred_mat'] = df.apply(lambda row: restore_pred_matrix(row), axis=1)\n",
    "df['pred_array'] = df.apply(lambda row: restore_pred_list(row), axis=1)\n",
    "df['num_array'] = df.apply(lambda row:convert_num_to_list(row), axis=1)\n",
    "\n",
    "#print_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('/home/octusr3/project/oct/csv/0916.csv')\n",
    "meta_df = meta_df.drop_duplicates(subset=['image_path'])#删除image_path的重复元素，删除掉重复的image_path\n",
    "meta_df = meta_df[['image_path', 'age', 'floss', 'FP', 'FN']]\n",
    "meta_df['age'] = pd.to_numeric(meta_df['age'],errors='coerce')\n",
    "#print_df(meta_df)\n",
    "\n",
    "join_df = df.merge(meta_df, on='image_path')\n",
    "join_df = join_df.dropna()\n",
    "\n",
    "#print_df(join_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_for_R(df, col):\n",
    "    df = df.copy()\n",
    "    df = df[['image_path', 'eye', 'dates', 'age', 'FP', 'FN', 'floss', col]]\n",
    "    df = df.rename(columns={\n",
    "        'image_path': 'id', \n",
    "        'dates': 'date', \n",
    "        'FP': 'fpr', \n",
    "        'FN': 'fnr', \n",
    "        'floss': 'fl'\n",
    "    })\n",
    "    df[[f'l{i}' for i in range(1, 55)]] = pd.DataFrame(df[col].tolist(), index= df.index)#这个比melt好用多了，melt融化数据很麻烦，非常复杂，弄得很复杂，最后还不如直接tolist() 构建新的数据集再join\n",
    "    df = df.drop(columns=[col])\n",
    "    df['time'] = '00:00:00'\n",
    "    df['type'] = 'pwg'\n",
    "    df['duration'] = '00:06:00'\n",
    "    df = df[['id','eye','date','time','age','type','fpr','fnr','fl','duration'] + [f'l{i}' for i in range(1, 55)]]\n",
    "    return df\n",
    "\n",
    "df4R = extract_list_for_R(join_df, 'num_array')\n",
    "df4R.to_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_num.csv', index=False)\n",
    "\n",
    "df4R = extract_list_for_R(join_df, 'pred_array')\n",
    "df4R.to_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc99d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/octusr3/project/oct/output/1102/disc_num_r50_512/exp-pid/results/valid-loss/df4R_pred.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_pred.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指标计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/octusr3/project/oct/output/1005/macula_num_r50_380/exp-pid/results/valid-loss/df4R_num_pdp.csv\n",
      "/home/octusr3/project/oct/output/1102/disc_num_r50_512/exp-pid/results/valid-loss/df4R_num_pdp.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def get_metrics(exp_name, name):\n",
    "    valid_cols = [f'l{i}' for i in range(1, 55)]\n",
    "    valid_cols.remove('l26')\n",
    "    valid_cols.remove('l35')\n",
    "    \n",
    "    df_num = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_num.csv')\n",
    "    df_pred = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_pred.csv')\n",
    "    num = df_num[valid_cols].values\n",
    "    pred = df_pred[valid_cols].values\n",
    "    mae = mean_absolute_error(num, pred)\n",
    "    \n",
    "    df_num = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_num_pdp.csv')\n",
    "    df_pred = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_pred_pdp.csv')\n",
    "    \n",
    "    class_mapping = {\n",
    "        0: 1,\n",
    "        0.005: 1,\n",
    "        0.01: 1,\n",
    "        0.02: 1,\n",
    "        0.05: 1,\n",
    "        0.95: 0,\n",
    "        0.98: 0,\n",
    "        0.99: 0,\n",
    "        0.995: 0,\n",
    "        1: 0,\n",
    "    }\n",
    "    for col in valid_cols:\n",
    "        df_num[col] = df_num[col].map(class_mapping)\n",
    "        df_pred[col] = df_pred[col].map(class_mapping)\n",
    "\n",
    "    y_true = df_num[valid_cols].values.reshape(-1)\n",
    "    y_pred = df_pred[valid_cols].values.reshape(-1)\n",
    "\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "\n",
    "    acc = (TP + TN) / (TP + FP + FN + TN)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (FP + TN)\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    df_num = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_num_pdp.csv')\n",
    "    df_pred = pd.read_csv(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_pred_pdp.csv')\n",
    "    print(f'{root_path}/{exp_name}/exp-pid/results/valid-loss/df4R_num_pdp.csv')\n",
    "    class_mapping = {\n",
    "        0: 4,\n",
    "        0.005: 4,\n",
    "        0.01: 3,\n",
    "        0.02: 2,\n",
    "        0.05: 1,\n",
    "        0.95: 0,\n",
    "        0.98: 0,\n",
    "        0.99: 0,\n",
    "        0.995: 0,\n",
    "        1: 0,\n",
    "    }\n",
    "    for col in valid_cols:\n",
    "        df_num[col] = df_num[col].map(class_mapping)\n",
    "        df_pred[col] = df_pred[col].map(class_mapping)\n",
    "\n",
    "    y_true = df_num[valid_cols].values.reshape(-1)\n",
    "    y_pred = df_pred[valid_cols].values.reshape(-1)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    _, _, fscores, _ = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return {\n",
    "        'exp name': name,\n",
    "        \n",
    "        ('Regression', 'mae'): f'{mae:.3f}',\n",
    "        \n",
    "        ('2-class', 'accuracy'): f'{acc:.3f}',\n",
    "        ('2-class', 'sensitivity'): f'{sensitivity:.3f}',\n",
    "        ('2-class', 'specificity'): f'{specificity:.3f}',\n",
    "        ('2-class', 'precision'): f'{precision:.3f}',\n",
    "        ('2-class', 'recall'): f'{recall:.3f}',\n",
    "        ('2-class', 'f1'): f'{F1:.3f}',\n",
    "        \n",
    "        ('5-class', '0.95-f1'): f'{fscores[0]:.3f}',\n",
    "        ('5-class', '0.05-f1'): f'{fscores[1]:.3f}',\n",
    "        ('5-class', '0.02-f1'): f'{fscores[2]:.3f}',\n",
    "        ('5-class', '0.01-f1'): f'{fscores[3]:.3f}',\n",
    "        ('5-class', '0.005-f1'): f'{fscores[4]:.3f}',\n",
    "        \n",
    "        ('5-class', 'macro-f1'): f'{macro_f1:.3f}',\n",
    "        ('5-class', 'micro-f1'): f'{micro_f1:.3f}',\n",
    "    }\n",
    "df_stat = []\n",
    "df_stat.append(get_metrics('1005/macula_num_r50_380', 'Macula'))\n",
    "df_stat.append(get_metrics('1102/disc_num_r50_512', 'Disc'))\n",
    "\n",
    "keys = [('Regression', 'mae'),\n",
    "        ('2-class', 'accuracy'),\n",
    "        ('2-class', 'sensitivity'),\n",
    "        ('2-class', 'specificity'),\n",
    "        ('2-class', 'precision'),\n",
    "        ('2-class', 'recall'),\n",
    "        ('2-class', 'f1'),\n",
    "        \n",
    "        ('5-class', '0.95-f1'),\n",
    "        ('5-class', '0.05-f1'),\n",
    "        ('5-class', '0.02-f1'),\n",
    "        ('5-class', '0.01-f1'),\n",
    "        ('5-class', '0.005-f1'),\n",
    "        \n",
    "        ('5-class', 'macro-f1'),\n",
    "        ('5-class', 'micro-f1')]\n",
    "df_stat = pd.DataFrame(df_stat, index=['Macula', 'Disc'], columns=pd.MultiIndex.from_tuples(keys))\n",
    "#df_stat = df_stat.set_index('exp name')\n",
    "#print_df(df_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Regression</th>\n",
       "      <th colspan=\"6\" halign=\"left\">2-class</th>\n",
       "      <th colspan=\"7\" halign=\"left\">5-class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>0.95-f1</th>\n",
       "      <th>0.05-f1</th>\n",
       "      <th>0.02-f1</th>\n",
       "      <th>0.01-f1</th>\n",
       "      <th>0.005-f1</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>micro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Macula</th>\n",
       "      <td>4.250</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disc</th>\n",
       "      <td>3.214</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Regression  2-class                                                  \\\n",
       "              mae accuracy sensitivity specificity precision recall     f1   \n",
       "Macula      4.250    0.639       0.374       0.680     0.155  0.374  0.220   \n",
       "Disc        3.214    0.789       0.174       0.889     0.202  0.174  0.187   \n",
       "\n",
       "       5-class                                                     \n",
       "       0.95-f1 0.05-f1 0.02-f1 0.01-f1 0.005-f1 macro-f1 micro-f1  \n",
       "Macula   0.765   0.054   0.023   0.023    0.145    0.202    0.612  \n",
       "Disc     0.879   0.045   0.021   0.017    0.137    0.220    0.776  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "623a9f8af0be4123d72a49457fdd65b442f8fe6d5b5109249813d94319742a73"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
