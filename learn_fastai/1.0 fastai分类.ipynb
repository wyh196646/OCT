{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b4ac06-876a-41b7-b809-ca64a1f0e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a60770e-4fa3-4ccb-b54e-2f52ccfd2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd400ce-1747-4ddf-83df-f5e3b87b3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 get_items=get_image_files,\n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                 item_tfms=Resize(460),\n",
    "                 batch_tfms=aug_transforms(size=224, min_scale=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb5359b-b258-4c10-98e4-9d0308acc60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from /home/octusr2/.fastai/data/oxford-iiit-pet/images\n",
      "Found 7390 items\n",
      "2 datasets of sizes 5912,1478\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: PILBase.create\n",
      "    starting from\n",
      "      /home/octusr2/.fastai/data/oxford-iiit-pet/images/Bengal_49.jpg\n",
      "    applying PILBase.create gives\n",
      "      PILImage mode=RGB size=500x333\n",
      "  Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "    starting from\n",
      "      /home/octusr2/.fastai/data/oxford-iiit-pet/images/Bengal_49.jpg\n",
      "    applying partial gives\n",
      "      Bengal\n",
      "    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n",
      "      TensorCategory(1)\n",
      "\n",
      "Final sample: (PILImage mode=RGB size=500x333, TensorCategory(1))\n",
      "\n",
      "\n",
      "Collecting items from /home/octusr2/.fastai/data/oxford-iiit-pet/images\n",
      "Found 7390 items\n",
      "2 datasets of sizes 5912,1478\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n",
      "Setting up after_item: Pipeline: Resize -- {'size': (460, 460), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Flip -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} -> RandomResizedCropGPU -- {'size': (224, 224), 'min_scale': 0.75, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'max_scale': 1.0, 'p': 1.0} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}\n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: Resize -- {'size': (460, 460), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n",
      "    starting from\n",
      "      (PILImage mode=RGB size=500x333, TensorCategory(1))\n",
      "    applying Resize -- {'size': (460, 460), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n",
      "      (PILImage mode=RGB size=460x460, TensorCategory(1))\n",
      "    applying ToTensor gives\n",
      "      (TensorImage of size 3x460x460, TensorCategory(1))\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "Applying batch_tfms to the batch built\n",
      "  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Flip -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} -> RandomResizedCropGPU -- {'size': (224, 224), 'min_scale': 0.75, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'max_scale': 1.0, 'p': 1.0} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}\n",
      "    starting from\n",
      "      (TensorImage of size 4x3x460x460, TensorCategory([ 1, 14, 14, 17], device='cuda:0'))\n",
      "    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n",
      "      (TensorImage of size 4x3x460x460, TensorCategory([ 1, 14, 14, 17], device='cuda:0'))\n",
      "    applying Flip -- {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'mode_mask': 'nearest', 'align_corners': True, 'p': 0.5} gives\n",
      "      (TensorImage of size 4x3x460x460, TensorCategory([ 1, 14, 14, 17], device='cuda:0'))\n",
      "    applying RandomResizedCropGPU -- {'size': (224, 224), 'min_scale': 0.75, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'max_scale': 1.0, 'p': 1.0} gives\n",
      "      (TensorImage of size 4x3x224x224, TensorCategory([ 1, 14, 14, 17], device='cuda:0'))\n",
      "    applying Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False} gives\n",
      "      (TensorImage of size 4x3x224x224, TensorCategory([ 1, 14, 14, 17], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octusr2/anaconda3/envs/fastai_oct/lib/python3.8/site-packages/torch/_tensor.py:1051: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272128894/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pets.summary(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29faa6b2-8cdb-4b8a-898f-21db775410c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/octusr2/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cce94ec5044492295fff0bbf737956f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.457368</td>\n",
       "      <td>0.351248</td>\n",
       "      <td>0.117050</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.502715</td>\n",
       "      <td>0.308578</td>\n",
       "      <td>0.100812</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.321582</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.075778</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = pets.dataloaders(path/\"images\")\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ef42d-0451-445a-a3b0-3559c93443bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oct_39]",
   "language": "python",
   "name": "conda-env-oct_39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
